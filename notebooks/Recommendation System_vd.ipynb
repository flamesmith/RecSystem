{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abPiqx1U-Q1P"
   },
   "source": [
    "## **Join reviews data with item metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12425,
     "status": "ok",
     "timestamp": 1771154271973,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "d3s-OXSpwgA5"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "from contextlib import redirect_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1771154271981,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "fUSVg_JK-LKb"
   },
   "outputs": [],
   "source": [
    "# Set display option to show full content of columns\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "# Turn off scientific notation for pandas DataFrames\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1771154769899,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "45f03f5d",
    "outputId": "6e1b314a-d8d6-4562-d14b-ec6e1fd2e3be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory /content/drive/MyDrive/RecEng_data/ does not exist. Please check your Google Drive path.\n",
      "You might need to adjust 'path_to_check' to '/content/drive/MyDrive/' to see the main contents of your Drive.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_to_check = '/content/drive/MyDrive/RecEng_data/'\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(path_to_check):\n",
    "    print(f\"Contents of {path_to_check}:\")\n",
    "    for item in os.listdir(path_to_check):\n",
    "        print(item)\n",
    "else:\n",
    "    print(f\"The directory {path_to_check} does not exist. Please check your Google Drive path.\")\n",
    "    print(\"You might need to adjust 'path_to_check' to '/content/drive/MyDrive/' to see the main contents of your Drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "error",
     "timestamp": 1771154777689,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "wPcHAOx8o50Q",
    "outputId": "ebb591ed-5eaa-45c4-8d41-4a37861d5292"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/RecEng_data/Home_and_Kitchen_filtered.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2247623323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Take the dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/RecEng_data/Home_and_Kitchen_filtered.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/RecEng_data/meta_Home_and_Kitchen_filtered.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/RecEng_data/Home_and_Kitchen_filtered.csv'"
     ]
    }
   ],
   "source": [
    "# Take the dataframes\n",
    "file_reviews = '/content/drive/MyDrive/RecEng_data/Home_and_Kitchen_filtered.csv'\n",
    "df_reviews = pd.read_csv(file_reviews)\n",
    "\n",
    "file_items = '/content/drive/MyDrive/RecEng_data/meta_Home_and_Kitchen_filtered.csv'\n",
    "df_items = pd.read_csv(file_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134011,
     "status": "aborted",
     "timestamp": 1771154393386,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "gOb-mgzM-QKh"
   },
   "outputs": [],
   "source": [
    "# Merge reviews with items using left_join\n",
    "df_combined = df_reviews.merge(df_items, left_on='asin', right_on='asin', how = 'left')\n",
    "\n",
    "# Convert 'unixReviewTime' to datetime format\n",
    "df_combined['unixReviewTime'] = pd.to_datetime(df_combined['unixReviewTime'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134011,
     "status": "aborted",
     "timestamp": 1771154393387,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "79c1a587"
   },
   "outputs": [],
   "source": [
    "def df_information(df):\n",
    "    \"\"\"\n",
    "    Returns essential information about a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "              - 'shape': tuple of (rows, columns)\n",
    "              - 'info': string output of df.info()\n",
    "              - 'numerical_summary': summary statistics for numerical columns\n",
    "              - 'numerical_cols': list of numerical column names\n",
    "              - 'categorical_cols': list of categorical/object column names\n",
    "              - 'missing_values': Series of missing values sorted descending\n",
    "              - 'Number of Duplicates': count of duplicate rows\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "\n",
    "    # 1. Shape of the DataFrame\n",
    "    info['shape'] = df.shape\n",
    "\n",
    "    # 2. General information (like df.info())\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        df.info(verbose=True, show_counts=True)\n",
    "    info['info'] = f.getvalue()\n",
    "\n",
    "    # 3. Summary Statistics for numerical columns\n",
    "    info['numerical_summary'] = df.describe()\n",
    "\n",
    "    # 4. Identify Numerical and Categorical Variables\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    info['numerical_cols'] = numerical_cols\n",
    "    info['categorical_cols'] = categorical_cols\n",
    "\n",
    "    # 5. Missing Values\n",
    "    missing_values = df.isnull().sum()\n",
    "    info['missing_values'] = missing_values.sort_values(ascending=False)\n",
    "\n",
    "    # 6. Number of Duplicates\n",
    "    info['duplicates'] = df.duplicated().sum()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134011,
     "status": "aborted",
     "timestamp": 1771154393387,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "8Y_dxosUuw-8"
   },
   "outputs": [],
   "source": [
    "df_info = df_information(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134011,
     "status": "aborted",
     "timestamp": 1771154393388,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "i6NdXhfd1oKu"
   },
   "outputs": [],
   "source": [
    "# Check the df_info\n",
    "for i in df_info.keys():\n",
    "  print(f\"{i}:\\n{df_info[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1771154393389,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "PHaFBDcy6tDT"
   },
   "outputs": [],
   "source": [
    "# Check for different combinations for missing values\n",
    "df_combined[(df_combined['rank'].isnull() == True) &\n",
    "            (df_combined['description'].isnull() == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "aborted",
     "timestamp": 1771154393389,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "4vDzHw5qAwlN"
   },
   "outputs": [],
   "source": [
    "# Drop duplicate rows from df_combined\n",
    "df_combined.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDTprOwO2kpr"
   },
   "source": [
    "**General Summary**\n",
    "\n",
    "*   Data has **7.2M rows and 18 columns**\n",
    "*   Data has 1 **numerical** variable (rating). The rest are **categorical** variables.\n",
    "*   The **reviews** are skewed to high, with 25 percentile being 4 or above.\n",
    "*   We have aound **570k duplicates**. This can be because we removed the reviewText variable (probably a user wrote multiple reviews)\n",
    "*   Variables **\"category\", \"description\", \"rank\", and \"feature\"** are always missing together\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kItztsxE8AkU"
   },
   "source": [
    "## **Analysis with Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjOg0y6F8Kat"
   },
   "source": [
    "**Purpuse**\n",
    "Since for the basic modeling we do not need **context information (e.g., style, category)**, we will take the 3 variables for the current analysis: **userId, rating, time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134007,
     "status": "aborted",
     "timestamp": 1771154393390,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "4de636c2"
   },
   "outputs": [],
   "source": [
    "# Print the 1st row\n",
    "display(df_combined.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134007,
     "status": "aborted",
     "timestamp": 1771154393390,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "MpiM4MkP__hg"
   },
   "outputs": [],
   "source": [
    "# Take the subset to analys\n",
    "df_subset = df_combined[['overall', 'reviewerID', 'asin', 'unixReviewTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134006,
     "status": "aborted",
     "timestamp": 1771154393392,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "jA8ya-Uh8f3P"
   },
   "outputs": [],
   "source": [
    "# Check number of rows and number of unique reviewers\n",
    "\n",
    "print(f'Number of total rows:', df_subset.shape[0])\n",
    "print(f'Number of total reviewerIDs', df_subset['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134003,
     "status": "aborted",
     "timestamp": 1771154393392,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "dUC_b55a8Jvg"
   },
   "outputs": [],
   "source": [
    "# Count the number of unique items (asin) purchased by each user (reviewerID)\n",
    "items_per_user = df_subset.groupby('reviewerID')['asin'].nunique()\n",
    "\n",
    "# Create a histogram of the distribution of items purchased per user\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.histplot(items_per_user, bins=range(1, items_per_user.max() + 2), kde=False)\n",
    "plt.title('Distribution of Number of Unique Items Purchased Per User')\n",
    "plt.xlabel('Number of Unique Items Purchased')\n",
    "plt.ylabel('Number of Users')\n",
    "\n",
    "# Get current x-axis limits and generate ticks for every 10th value\n",
    "max_items = items_per_user.max()\n",
    "plt.xticks(range(1, max_items + 1, 30))\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134000,
     "status": "aborted",
     "timestamp": 1771154393392,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "o95Z7nlSEjEO"
   },
   "outputs": [],
   "source": [
    "# Distribution of number of items rated\n",
    "items_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133998,
     "status": "aborted",
     "timestamp": 1771154393393,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "1vDtUTsSEwmh"
   },
   "outputs": [],
   "source": [
    "# This counts how many users bought 1 item, how many bought 2 items, etc.\n",
    "users_by_items_purchased = items_per_user.value_counts().sort_index()\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "df_users_by_items = users_by_items_purchased.reset_index()\n",
    "df_users_by_items.columns = ['Number of Unique Items Purchased', 'Number of Users']\n",
    "\n",
    "\n",
    "df_users_by_items.sort_values(['Number of Users'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133996,
     "status": "aborted",
     "timestamp": 1771154393393,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "2voYpKY2Ewo3"
   },
   "outputs": [],
   "source": [
    "# Number of reviews by user\n",
    "items_per_user.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133994,
     "status": "aborted",
     "timestamp": 1771154393394,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "D1sc64yDEwrK"
   },
   "outputs": [],
   "source": [
    "# Visualize average rating over time\n",
    "# # Extract year from reviewTime for time-based analysis\n",
    "df_subset['review_year'] = df_subset['unixReviewTime'].dt.year\n",
    "\n",
    "# 1. Average Rating Over Time\n",
    "average_ratings_by_year = df_subset.groupby('review_year')['overall'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='review_year', y='overall', data=average_ratings_by_year, marker='o')\n",
    "plt.title('Average Overall Rating Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.grid(True)\n",
    "# Set x-ticks to display integer years\n",
    "plt.xticks(average_ratings_by_year['review_year'].unique(), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133992,
     "status": "aborted",
     "timestamp": 1771154393394,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "GjIWBSlX7ziC"
   },
   "outputs": [],
   "source": [
    "# 2. Distribution of Each Rating (1-5) Over Time\n",
    "# Count occurrences of each rating per year\n",
    "rating_distribution_by_year = df_subset.groupby(['review_year', 'overall']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plotting the distribution as a stacked bar chart or separate lines\n",
    "plt.figure(figsize=(14, 7))\n",
    "rating_distribution_by_year.plot(kind='bar', stacked=True, figsize=(14, 7))\n",
    "plt.title('Distribution of Overall Ratings (1-5) Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Rating', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, as separate line plots for clearer trends of each rating\n",
    "plt.figure(figsize=(14, 7))\n",
    "for rating in sorted(df_subset['overall'].unique()):\n",
    "    sns.lineplot(x=rating_distribution_by_year.index, y=rating_distribution_by_year[rating], label=f'Rating {rating}', marker='o')\n",
    "\n",
    "plt.title('Trend of Individual Overall Ratings Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKJ3fH_HIuyd"
   },
   "source": [
    "## **Create function to return <u>the most popular items</u> up to a date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133992,
     "status": "aborted",
     "timestamp": 1771154393395,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "hMSVTga6Cp7s"
   },
   "outputs": [],
   "source": [
    "def get_topn_popular_items(df, user_id, timestamp, n):\n",
    "    \"\"\"\n",
    "    Returns the top-N most popular items up to a given timestamp\n",
    "    that the user has NOT purchased yet.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns ['reviewerID', 'asin', 'unixReviewTime']\n",
    "    - user_id: the ID of the user (corresponds to 'reviewerID')\n",
    "    - timestamp: cutoff time (recommend items purchased BEFORE this timestamp)\n",
    "    - n: number of items to recommend\n",
    "\n",
    "    Returns:\n",
    "    - list of top-N item_ids (ASINs)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Filter data up to the given timestamp using 'unixReviewTime'\n",
    "    df_up_to_t = df[df['unixReviewTime'] < timestamp]\n",
    "\n",
    "    # 2️⃣ Get items the user has already purchased using 'reviewerID' and 'asin'\n",
    "    user_purchased = set(df_up_to_t[df_up_to_t['reviewerID'] == user_id]['asin'])\n",
    "\n",
    "    # 3️⃣ Count popularity of each item (number of purchases) using 'asin'\n",
    "    item_counts = df_up_to_t.groupby('asin').size().sort_values(ascending=False)\n",
    "\n",
    "    # 4️⃣ Filter out items the user has already purchased\n",
    "    top_items = [item for item in item_counts.index if item not in user_purchased]\n",
    "\n",
    "    # 5️⃣ Return top-N\n",
    "    return top_items[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133992,
     "status": "aborted",
     "timestamp": 1771154393395,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "8GQDgTHMHMdX"
   },
   "outputs": [],
   "source": [
    "def get_items_purchased_after_cutoff(df, user_id, cutoff_date):\n",
    "    \"\"\"\n",
    "    Returns a list of unique items (ASINs) purchased by a given user\n",
    "    after a specified cutoff date.\n",
    "\n",
    "    Args:\n",
    "        user_id (str): The ID of the user.\n",
    "        cutoff_date (pd.Timestamp): The date after which to consider purchases.\n",
    "        df (pd.DataFrame): The DataFrame containing 'reviewerID', 'asin', and 'unixReviewTime'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique ASINs purchased by the user after the cutoff date.\n",
    "    \"\"\"\n",
    "    # Filter for the specific user and purchases after the cutoff date\n",
    "    purchases_after_cutoff = df[\n",
    "        (df['reviewerID'] == user_id) &\n",
    "        (df['unixReviewTime'] > cutoff_date)\n",
    "    ]\n",
    "\n",
    "    # Return unique ASINs from these purchases\n",
    "    return purchases_after_cutoff['asin'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj6Yl1Fp_tfG"
   },
   "source": [
    "## **Create function to return <u>the highest items</u> up to a date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133992,
     "status": "aborted",
     "timestamp": 1771154393395,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "AnVxWAXN2j0W"
   },
   "outputs": [],
   "source": [
    "def get_topn_reviewed_items(df, user_id, timestamp, review_sample, n):\n",
    "    \"\"\"\n",
    "    Returns the top-N highest reviewed items with review_sample threshold up to a given timestamp\n",
    "    that the user has NOT purchased yet.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns ['reviewerID', 'asin', 'unixReviewTime']\n",
    "    - user_id: the ID of the user (corresponds to 'reviewerID')\n",
    "    - timestamp: cutoff time (recommend items purchased BEFORE this timestamp)\n",
    "    - review_sample: cutoff on number of reviews to consider for ranking the reviews\n",
    "    - n: number of items to recommend\n",
    "\n",
    "    Returns:\n",
    "    - list of top-N item_ids (ASINs)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Filter data up to the given timestamp using 'unixReviewTime'\n",
    "    df_up_to_t = df[df['unixReviewTime'] < timestamp]\n",
    "\n",
    "    # 2️⃣ Get items the user has already purchased using 'reviewerID' and 'asin'\n",
    "    user_purchased = set(df_up_to_t[df_up_to_t['reviewerID'] == user_id]['asin'])\n",
    "\n",
    "    # 3️⃣ Count popularity of each item (number of purchases) using 'asin'\n",
    "    avg_ratings = df_subset.groupby('asin').agg({'overall' : 'mean', 'unixReviewTime' : 'count'}).reset_index()\n",
    "    avg_ratings.columns = ['asin', 'avg_rating', 'num_ratings']\n",
    "    avg_ratings = avg_ratings[avg_ratings['num_ratings'] > review_sample].copy()\n",
    "    avg_ratings.sort_values(by = 'avg_rating', ascending = False, inplace = True)\n",
    "\n",
    "    # 4️⃣ Filter out items the user has already purchased\n",
    "    top_items = [item for item in list(avg_ratings['avg_rating']) if item not in user_purchased]\n",
    "\n",
    "    # 5️⃣ Return top-N\n",
    "    return top_items[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRRp5oFo_5YP"
   },
   "source": [
    "## **Create function to return <u>the items based on co occurrence</u> up to a date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Viyg1_e_9fd"
   },
   "outputs": [],
   "source": [
    "def compute_cooccurrence_before_timestamp(df, cutoff_timestamp):\n",
    "    \"\"\"\n",
    "    Computes item-item co-occurrence matrix using only interactions\n",
    "    before the given cutoff timestamp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must contain columns: ['user_id', 'item_id', 'timestamp']\n",
    "    cutoff_timestamp : str or pd.Timestamp\n",
    "        Use only data before this time.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    co_matrix : pandas.DataFrame\n",
    "        Item-item co-occurrence matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Filter data before cutoff\n",
    "    df_filtered = df[df[\"timestamp\"] < cutoff_timestamp]\n",
    "\n",
    "    # 2️⃣ Create user-item matrix (binary)\n",
    "    user_item = (\n",
    "        df_filtered\n",
    "        .drop_duplicates([\"user_id\", \"item_id\"])  # ensure binary\n",
    "        .assign(value=1)\n",
    "        .pivot(index=\"user_id\", columns=\"item_id\", values=\"value\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # 3️⃣ Convert to numpy array\n",
    "    X = user_item.values\n",
    "\n",
    "    # 4️⃣ Compute co-occurrence matrix\n",
    "    co_matrix = X.T @ X\n",
    "\n",
    "    # 5️⃣ Convert back to DataFrame\n",
    "    co_matrix = pd.DataFrame(\n",
    "        co_matrix,\n",
    "        index=user_item.columns,\n",
    "        columns=user_item.columns\n",
    "    )\n",
    "\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5DyKb1FJbJn"
   },
   "source": [
    "## **Create functions for model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnGXiioeQYDV"
   },
   "source": [
    "**Example**\n",
    "We consider 2 users with **top-5 recommended items**:\n",
    "\n",
    "- User 1 purchased items `{A, C}`  \n",
    "- User 2 purchased items `{B}`  \n",
    "- Recommendations for both users (top-5): `[A, B, C, D, E]`\n",
    "\n",
    "---\n",
    "\n",
    "| Metric | Formula | Description | Example (2 users, 5 recommended items) |\n",
    "|--------|---------|-------------|----------------------------------------|\n",
    "| **Precision@K** | $$\\text{Precision@K}_u = \\frac{|R_u^K \\cap P_u|}{K}$$ | Fraction of top-K recommended items that were actually purchased. In other words, TP/(TP+TN). If we recommend 5 items, and user later purchased 2 out of 5, then the precision is 2/5 = 0.4. The final is the average of all the precision scores for all the users.| **User 1:** 2/5 = 0.4 <br> **User 2:** 1/5 = 0.2 <br> **Average:** (0.4 + 0.2)/2 = 0.3 |\n",
    "| **Recall@K** | $$\\text{Recall@K}_u = \\frac{|R_u^K \\cap P_u|}{|P_u|}$$ | Fraction of all purchased items that appear in top-K recommendations. In other words, TP/(TP + FN). If the user purchased 3 items after we make the recommendations and out of the 3, 2 were in the list of 5 products that we recommended, then the recall is 2/3 = 0.66. The final is the average of all the precisions scores for all the users.| **User 1:** 2/2 = 1.0 <br> **User 2:** 1/1 = 1.0 <br> **Average:** (1.0 + 1.0)/2 = 1.0 |\n",
    "| **Hit@K** | $$\\text{Hit@K}_u = \\begin{cases} 1 & \\text{if } |R_u^K \\cap P_u| \\ge 1 \\\\ 0 & \\text{otherwise} \\end{cases}$$ | Binary metric: Did the user get **at least one relevant item** in the top-K? For example, if out of 5 items recommend the user later purchased >= 1, then the hit rate is 1 for that user (0 otherwise). The total hit rate is the avearege of all the hit rates for the user. | **User 1:** 1 <br> **User 2:** 0 (none of the recommended items were purhcased) <br> **Average:** (1+0)/2 = 0.5 |\n",
    "| **DCG@K** | $$DCG@K = \\sum_{i=1}^{K} \\frac{rel_i}{\\log_2(i+1)}$$ | Discounted Cumulative Gain measures **ranking quality**, giving more weight to relevant items appearing at the top. The matric is used to calculate **NDCG@k**. For example, if the order of items recommende is [A, B, C, D, E] and the user later purchased [A, C], then DCG@K equals 1/log2(2) + 0/log2(3) + 1/log2(4)... = 1.5| **User 1:** relevance `[1,0,1,0,0]` → DCG = 1/1 + 0 + 1/2 = 1.5 <br> **User 2:** relevance `[0,1,0,0,0]` → DCG = 1/1.585 ≈ 0.63 |\n",
    "| **IDCG@K** | $$IDCG@K = \\sum_{i=1}^{|P_u|} \\frac{1}{\\log_2(i+1)}$$ | Ideal DCG: maximum possible DCG if all purchased items are ranked at the top. Again, is used to calculade NDCG@k. It calculates the best possible scenario based on the user's purchases. For example, since the user pruchased [A, C] the ideal recommendation would have been [A, C, _, _, _] and the ideal value would have been 1/log2(2) + 1/log2(3) = 1.63| **User 1:** 2 items purchased → IDCG = 1/1 + 1/1.585 ≈ 1 + 0.63 = 1.63 <br> **User 2:** 1 item purchased → IDCG = 1/1 = 1 |\n",
    "| **NDCG@K** | $$NDCG@K = \\frac{DCG@K}{IDCG@K}$$ | Normalized DCG: rank-aware metric (0–1). Rewards having relevant items **near the top**. Is calculated by DCG@k/IDCG@K and from the example above equals to 1.5/1.63 = 0.92| **User 1:** 1.5 / 1.63 ≈ 0.92 <br> **User 2:** 0.63 / 1 ≈ 0.63 <br> **Average:** (0.92+0.63)/2 ≈ 0.775 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "96cc23b5"
   },
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(recommended_items, actual_purchases, k):\n",
    "    \"\"\"\n",
    "    Calculates Precision@K for a single user.\n",
    "\n",
    "    Args:\n",
    "        recommended_items (list): A list of recommended items.\n",
    "        actual_purchases (list): A list of items actually purchased by the user.\n",
    "        k (int): The number of top recommended items to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: Precision@K score.\n",
    "    \"\"\"\n",
    "    top_k_recommended = recommended_items[:k]\n",
    "    if not top_k_recommended:\n",
    "        return 0.0\n",
    "\n",
    "    hits = len(set(top_k_recommended) & set(actual_purchases))\n",
    "    precision = hits / k\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-xTqs_7zLbFC"
   },
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(recommended_items, actual_purchases, k):\n",
    "    \"\"\"\n",
    "    Calculates Recall@K for a single user.\n",
    "\n",
    "    Args:\n",
    "        recommended_items (list): A list of recommended items.\n",
    "        actual_purchases (list): A list of items actually purchased by the user.\n",
    "        k (int): The number of top recommended items to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: Recall@K score.\n",
    "    \"\"\"\n",
    "    if not actual_purchases:\n",
    "        return 0.0  # or optionally skip this user when averaging\n",
    "\n",
    "    top_k_recommended = recommended_items[:k]\n",
    "    hits = len(set(top_k_recommended) & set(actual_purchases))\n",
    "    recall = hits / len(actual_purchases)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "m7Ob0tBlYnj1"
   },
   "outputs": [],
   "source": [
    "def calculate_hit_at_k(recommended_items, actual_purchases, k):\n",
    "    \"\"\"\n",
    "    Calculates Hit@K for a single user.\n",
    "\n",
    "    Args:\n",
    "        recommended_items (list): A list of recommended item ASINs.\n",
    "        actual_purchases (list): A list of item ASINs actually purchased by the user.\n",
    "        k (int): The number of top recommended items to consider for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        int: 1 if at least one recommended item in the top K is in actual purchases, 0 otherwise.\n",
    "    \"\"\"\n",
    "    # Take only the top k items from the recommended list\n",
    "    top_k_recommended_items = recommended_items[:k]\n",
    "\n",
    "    if not top_k_recommended_items or not actual_purchases:\n",
    "        return 0 # No hit if no recommendations or no actual purchases\n",
    "\n",
    "    # Convert actual_purchases to a set for efficient lookup\n",
    "    actual_purchases_set = set(actual_purchases)\n",
    "\n",
    "    # Check if any of the top k recommended items are in the actual purchases\n",
    "    for item in top_k_recommended_items:\n",
    "        if item in actual_purchases_set:\n",
    "            return 1 # Hit found\n",
    "\n",
    "    return 0 # No hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IkW4AiCbaLy3"
   },
   "outputs": [],
   "source": [
    "def calculate_dcg_at_k(recommended_items, actual_purchases, k):\n",
    "    \"\"\"\n",
    "    Calculates Discounted Cumulative Gain (DCG@K) for a single user.\n",
    "\n",
    "    Args:\n",
    "        recommended_items (list): A list of recommended item ASINs, ordered by relevance.\n",
    "        actual_purchases (list): A list of item ASINs actually purchased by the user.\n",
    "        k (int): The number of top recommended items to consider for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        float: The DCG@K score.\n",
    "    \"\"\"\n",
    "    top_k_recommended = recommended_items[:k]\n",
    "    if not top_k_recommended:\n",
    "        return 0.0\n",
    "\n",
    "    actual_purchases_set = set(actual_purchases)\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(top_k_recommended):\n",
    "        relevance = 1 if item in actual_purchases_set else 0\n",
    "        # Discount factor: log2(position + 1)\n",
    "        # Position is 0-indexed, so it's i+1. log2(i+1 + 1) = log2(i+2)\n",
    "        dcg += relevance / math.log2(i + 2)\n",
    "    return dcg\n",
    "\n",
    "def calculate_idcg_at_k(actual_purchases, k):\n",
    "    \"\"\"\n",
    "    Calculates Ideal Discounted Cumulative Gain (IDCG@K) for a single user.\n",
    "    This represents the maximum possible DCG if all relevant items were ranked at the top.\n",
    "\n",
    "    Args:\n",
    "        actual_purchases (list): A list of item ASINs actually purchased by the user.\n",
    "        k (int): The number of top positions to consider for the ideal ranking.\n",
    "\n",
    "    Returns:\n",
    "        float: The IDCG@K score.\n",
    "    \"\"\"\n",
    "    if not actual_purchases:\n",
    "        return 0.0\n",
    "\n",
    "    # The ideal scenario is to place all relevant items (up to k) at the top\n",
    "    # We assume relevance = 1 for all actual purchases\n",
    "    num_relevant_items = min(len(actual_purchases), k)\n",
    "    idcg = 0.0\n",
    "    for i in range(num_relevant_items):\n",
    "        # For ideal ranking, all relevant items have relevance = 1\n",
    "        idcg += 1 / math.log2(i + 2)\n",
    "    return idcg\n",
    "\n",
    "def calculate_ndcg_at_k(recommended_items, actual_purchases, k):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Discounted Cumulative Gain (NDCG@K) for a single user.\n",
    "\n",
    "    Args:\n",
    "        recommended_items (list): A list of recommended item ASINs, ordered by relevance.\n",
    "        actual_purchases (list): A list of item ASINs actually purchased by the user.\n",
    "        k (int): The number of top recommended items to consider for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        float: The NDCG@K score (value between 0 and 1).\n",
    "    \"\"\"\n",
    "    dcg = calculate_dcg_at_k(recommended_items, actual_purchases, k)\n",
    "    idcg = calculate_idcg_at_k(actual_purchases, k)\n",
    "\n",
    "    if idcg == 0:\n",
    "        return 0.0 # Cannot normalize if IDCG is zero (no actual purchases or k is 0)\n",
    "\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfShmoPQKw3-"
   },
   "source": [
    "## **Test Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4b074646"
   },
   "outputs": [],
   "source": [
    "user_id = 'A8LUWTIPU9CZB'\n",
    "cutoff_time = timestamp=pd.Timestamp('2015-11-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tTIueOppKzWZ"
   },
   "outputs": [],
   "source": [
    "items_recommended = get_topn_popular_items(df_subset,\n",
    "                                           user_id,\n",
    "                                           cutoff_time,\n",
    "                                           n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QJxZe4UCJejn"
   },
   "outputs": [],
   "source": [
    "items_purchased = get_items_purchased_after_cutoff(df_subset,\n",
    "                                                   user_id,\n",
    "                                                   cutoff_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1771073868950,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "0hLYnu0GF1vN",
    "outputId": "a5d11f94-8d3b-4a27-c8ae-189a17311fe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_precision_at_k(items_recommended, items_purchased, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1771073871608,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "qrDM2x8ZLJNP",
    "outputId": "70c72d82-e8ab-4156-e65d-2f8fb1d3172b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_recall_at_k(items_recommended, items_purchased, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1771076500921,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "EgrtX7ANYqHW",
    "outputId": "7ce3b640-7e26-48da-b1f7-4bcd275eb5d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_hit_at_k(items_recommended, items_purchased, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1771076936597,
     "user": {
      "displayName": "Lazr Galstyan",
      "userId": "08628736433354843666"
     },
     "user_tz": -240
    },
    "id": "0YjE-LHiLJP1",
    "outputId": "f533c58d-c402-42e8-f52b-f68497edf28a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_dcg_at_k(items_recommended, items_purchased, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzXTsK-rp26K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SMOtswWp3B8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "kItztsxE8AkU"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
